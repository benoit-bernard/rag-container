
### TODO
- remove duplicate
- add freshdesk data
- split qa service
- slipt main (routes)
- .config || .env > edit exe_change.bat
- create install.bat
- fix frontend endpoints/display
- better health check
- list files


### ğŸ“‹ PrÃ©requis
- Docker Desktop avec WSL2 activÃ©
- Windows 10/11 avec permissions administrateur

## ğŸ”§ Installation ComplÃ¨te

### 1. CrÃ©ation des Dossiers Volumes
```batch
mkdir volumes\ollama_data
mkdir volumes\shared_data\documents
mkdir volumes\shared_data\chroma_db
mkdir volumes\chroma_db
mkdir volumes\n8n_data

icacls volumes /grant "Tout le monde":F /T
```

### 2. âš ï¸ Setup Ollama 
```batch
REM DÃ©marrage initial
docker-compose up -d

REM âš ï¸ Ã‰TAPE CRITIQUE : Forcer la synchronisation volume
docker-compose stop ollama
docker rm -f project-ollama-1
rmdir /s /q volumes\ollama_data
mkdir volumes\ollama_data
docker-compose up -d ollama

REM Attendre le dÃ©marrage complet
timeout /t 60

REM TÃ©lÃ©charger le modÃ¨le dans le volume synchronisÃ©
exe_change_ollama_model.bat
```

### 3. âœ… VÃ©rification Obligatoire
```batch
REM Le modÃ¨le doit Ãªtre visible
docker exec project-ollama-1 ollama list

REM Le dossier Windows DOIT contenir des fichiers (pas juste 468 octets)
dir volumes\ollama_data /s

REM Test de persistance
docker-compose restart ollama
timeout /t 30
docker exec project-ollama-1 ollama list
```

### '4'. Build et DÃ©marrage Final
```batch
REM Build backend avec la correction
docker-compose build backend
docker-compose up -d

REM Ajouter un document test
echo "Document de test pour RAG" > volumes\shared_data\test.txt
```

## ğŸ“Š AccÃ¨s aux Services

- **Interface RAG** : http://localhost:8501
- **Backend API** : http://localhost:8000/health
- **Ollama API** : http://localhost:11434/api/tags
- **n8n Workflows** : http://localhost:5678

## ğŸ” Tests et Diagnostic

### Test Complet du SystÃ¨me
```batch
REM 1. SantÃ© des services
docker-compose ps

REM 2. ModÃ¨le Ollama prÃ©sent et persistant
docker exec project-ollama-1 ollama list
dir volumes\ollama_data /s

REM 3. Backend accessible
curl http://localhost:8000/health

REM 4. Test question simple
curl -X POST http://localhost:8000/ask -H "Content-Type: application/json" -d "{\"question\":\"Hello\"}"
```

### Diagnostic si ProblÃ¨me
```batch
REM Logs des services
docker logs project-backend-1
docker logs project-ollama-1
docker logs project-ui-1

REM VÃ©rifier connectivitÃ© Ollama depuis backend
docker exec project-backend-1 curl http://ollama:11434/api/tags

REM VÃ©rifier les volumes
docker inspect project-ollama-1 --format="{{range .Mounts}}{{.Source}} -> {{.Destination}}{{"\n"}}{{end}}"
```

## ğŸ”§ DÃ©veloppement (Build Safe)

```batch
REM âœ… Build backend seulement (prÃ©serve Ollama)
docker-compose build backend
docker-compose up -d backend

REM âœ… Build UI seulement
docker-compose build ui
docker-compose up -d ui

REM âŒ Ã‰VITER : docker-compose build (rebuild tout)
REM âŒ Ã‰VITER : docker-compose down (dÃ©truit les conteneurs)
```


## ğŸš¨ ProblÃ¨mes Connus et Solutions

### 1. Volume Ollama vide mais modÃ¨le prÃ©sent
**SymptÃ´me :**
```batch
docker exec project-ollama-1 ollama list  REM â†’ llama3.2:1b prÃ©sent
dir volumes\ollama_data /s                REM â†’ Seulement 468 octets
```

**Solution :**
```batch
docker-compose stop ollama
docker rm -f project-ollama-1
rmdir /s /q volumes\ollama_data && mkdir volumes\ollama_data
docker-compose up -d ollama
docker exec -it project-ollama-1 ollama pull llama3.2:1b
```

### 2. Backend erreur "Backend not ready"
**Causes possibles :**
- ModÃ¨le Ollama non disponible
- Mauvais nom de modÃ¨le dans `rag_server.py`
- Aucun document dans `shared_data/`

**Diagnostic :**
```batch
REM VÃ©rifier modÃ¨le disponible
docker exec project-ollama-1 ollama list

REM VÃ©rifier connectivitÃ©
curl http://localhost:11434/api/tags

REM VÃ©rifier documents
dir volumes\shared_data

REM Logs backend pour erreur dÃ©taillÃ©e
docker logs project-backend-1
```

### 3. Interface Streamlit ne charge pas
**VÃ©rifications :**
```batch
REM Service UI actif
docker-compose ps ui

REM Logs UI
docker logs project-ui-1

REM Port accessible
curl http://localhost:8501
```

## ğŸ”„ Workflow n8n

Dans n8n (http://localhost:5678), cliquer sur "Import" et coller :

```json
{
  "nodes": [
    {
      "parameters": {
        "url": "http://ollama:11434/api/generate",
        "method": "POST",
        "jsonParameters": true,
        "bodyParametersJson": "{\"model\": \"llama3.2:1b\", \"prompt\": \"{{$json.question}}\", \"stream\": false}"
      },
      "name": "Ollama API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 1,
      "position": [450, 300]
    }
  ],
  "connections": {}
}
```

## ğŸ“‹ Checklist Post-Setup

- [ ] Services actifs : `docker-compose ps`
- [ ] ModÃ¨le Ollama : `docker exec project-ollama-1 ollama list` â†’ llama3.2:1b visible
- [ ] Volume persistant : `dir volumes\ollama_data /s` â†’ Contient des fichiers (> 1MB)
- [ ] Backend accessible : `curl http://localhost:8000/health` â†’ status: ok
- [ ] Interface accessible : http://localhost:8501
- [ ] Test persistance : `docker-compose restart ollama` â†’ modÃ¨le toujours prÃ©sent
- [ ] Document test : `echo "Test" > volumes\shared_data\test.txt`

## ğŸ“ DÃ©pannage AvancÃ©

### Reset Complet
```batch
docker-compose down
docker system prune -f
rmdir /s /q volumes
mkdir volumes\ollama_data volumes\shared_data volumes\chroma_db volumes\n8n_data
icacls volumes /grant "Tout le monde":F /T
docker-compose up -d
REM Puis refaire le setup Ollama
```

### Sauvegarde
```batch
REM Sauvegarde complÃ¨te
xcopy volumes volumes_backup /E /H /Y

REM Sauvegarde modÃ¨le seulement
xcopy volumes\ollama_data ollama_backup /E /H /Y
```

## ğŸš€ Prochaines Ã‰tapes

- [ ] **Connexion Freshdesk API** - IntÃ©gration tickets support
- [ ] **Authentification** - SystÃ¨me utilisateurs
- [ ] **Monitoring** - Logs et mÃ©triques
- [ ] **DÃ©ploiement** - Production avec Docker Swarm/Kubernetes
- [ ] **Optimisation** - Cache et performance

## ğŸ“ˆ Maintenance

```batch
REM Nettoyage pÃ©riodique
docker system prune -f

REM Mise Ã  jour modÃ¨les
docker exec project-ollama-1 ollama pull llama3.2:1b

REM Backup automatique (Ã  automatiser)
xcopy volumes volumes_backup_%date% /E /H /Y
```

---

## âš¡ DÃ©marrage Rapide

```batch
REM Setup rapide complet
git clone [votre-repo]
cd project
mkdir volumes\ollama_data volumes\shared_data volumes\chroma_db volumes\n8n_data
icacls volumes /grant "Tout le monde":F /T
docker-compose up -d
docker-compose stop ollama && docker rm -f project-ollama-1
rmdir /s /q volumes\ollama_data && mkdir volumes\ollama_data
docker-compose up -d ollama
timeout /t 60
docker exec -it project-ollama-1 ollama pull llama3.2:1b
docker-compose build backend && docker-compose up -d
echo "Test RAG" > volumes\shared_data\test.txt
echo âœ… Setup terminÃ© - Interface: http://localhost:8501
```